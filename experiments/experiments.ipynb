{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset with 50 samples saved to /Users/wangxiang/Desktop/Startup-Success-Forecasting-Framework/data/Experiment_Dataset.csv\n",
      "Dataset shape: (50, 18)\n",
      "Successful companies: 10\n",
      "Unsuccessful companies: 40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Since we're in a notebook, we need to set the project root manually\n",
    "# Adjust this path according to your notebook's location relative to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Load the datasets\n",
    "unsuccessful_path = os.path.join(project_root, 'data', 'Merged_Unsuccessful_V2.csv')\n",
    "successful_path = os.path.join(project_root, 'data', 'Merged_Successful_V2.csv')\n",
    "\n",
    "unsuccessful_df = pd.read_csv(unsuccessful_path)\n",
    "successful_df = pd.read_csv(successful_path)\n",
    "\n",
    "# Add a 'success' column to each dataset\n",
    "unsuccessful_df['success'] = 0\n",
    "successful_df['success'] = 1\n",
    "\n",
    "# Randomly sample 40 rows from unsuccessful and 10 from successful\n",
    "unsuccessful_sample = unsuccessful_df.sample(n=40, random_state=42)\n",
    "successful_sample = successful_df.sample(n=10, random_state=42)\n",
    "\n",
    "# Concatenate the samples\n",
    "merged_sample = pd.concat([unsuccessful_sample, successful_sample], ignore_index=True)\n",
    "\n",
    "# Shuffle the merged dataset\n",
    "merged_sample = merged_sample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the merged sample\n",
    "output_path = os.path.join(project_root, 'data', 'Experiment_Dataset.csv')\n",
    "merged_sample.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Merged dataset with 50 samples saved to {output_path}\")\n",
    "print(f\"Dataset shape: {merged_sample.shape}\")\n",
    "print(f\"Successful companies: {merged_sample['success'].sum()}\")\n",
    "print(f\"Unsuccessful companies: {len(merged_sample) - merged_sample['success'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 org_name                              org_uuid  \\\n",
      "0        3080  Mytower  076d86c0-0ddb-414e-a7d1-4021d82e4f95   \n",
      "\n",
      "                                founder_linkedin_url  \\\n",
      "0  https://www.linkedin.com/in/meiri-shemesh-b673...   \n",
      "\n",
      "                                         json_string  \\\n",
      "0  {\"version\": 1, \"hits\": 1, \"results\": 1, \"kgver...   \n",
      "\n",
      "                                     structured_info  \\\n",
      "0  {'name': 'Meiri Shemesh', 'gender': '', 'birth...   \n",
      "\n",
      "                                           paragraph          domain  \\\n",
      "0  Meiri Shemesh is known for their contribution ...  mytowerapp.com   \n",
      "\n",
      "      status founded_on                                      category_list  \\\n",
      "0  operating     1/1/16  Internet of Things,Property Development,Proper...   \n",
      "\n",
      "                     category_groups_list country_code      city  \\\n",
      "0  Internet Services,Real Estate,Software          ISR  Tel Aviv   \n",
      "\n",
      "                                   short_description  \\\n",
      "0  A Unified All-in-One Innovative Property Intel...   \n",
      "\n",
      "                                    long_description  \\\n",
      "0  A Unified All-in-One Innovative Property Manag...   \n",
      "\n",
      "                                     integrated_info  success  \n",
      "0  Organisation's Name: Mytower Founder's Info: M...        0  \n"
     ]
    }
   ],
   "source": [
    "print(merged_sample.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 19:18:58,353 - INFO - Secrets loaded from /Users/wangxiang/Desktop/Startup-Success-Forecasting-Framework/.streamlit/secrets.toml\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(value)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Import your framework\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mssff_framework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StartupFramework\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Load the experiment dataset\u001b[39;00m\n\u001b[1;32m     36\u001b[0m input_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(project_root, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperiment_Dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/ssff_framework.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmarket_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MarketAgent\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproduct_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProductAgent\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfounder_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FounderAgent\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvc_scout_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VCScoutAgent, StartupInfo\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegration_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IntegrationAgent\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/agents/founder_agent.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Add the project root directory to the Python path\u001b[39;00m\n\u001b[1;32m      8\u001b[0m project_root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/myenv/lib/python3.11/site-packages/tensorflow/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/myenv/lib/python3.11/site-packages/tensorflow/python/pywrap_tensorflow.py:34\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m self_check\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mself_check\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreload_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m   \u001b[38;5;66;03m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;66;03m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/myenv/lib/python3.11/site-packages/tensorflow/python/platform/self_check.py:63\u001b[0m, in \u001b[0;36mpreload_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     51\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find the DLL(s) \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m. TensorFlow requires that these DLLs \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe installed in a directory that is named in your \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m           \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing))\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;66;03m# Load a library that performs CPU feature guard checking.  Doing this here\u001b[39;00m\n\u001b[1;32m     60\u001b[0m   \u001b[38;5;66;03m# as a preload check makes it more likely that we detect any CPU feature\u001b[39;00m\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;66;03m# incompatibilities before we trigger them (which would typically result in\u001b[39;00m\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;66;03m# SIGILL).\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_cpu_feature_guard\n\u001b[1;32m     64\u001b[0m   _pywrap_cpu_feature_guard\u001b[38;5;241m.\u001b[39mInfoAboutUnusedCPUFeatures()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import toml\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Load secrets\n",
    "secrets_path = Path(os.getcwd()).parent / '.streamlit' / 'secrets.toml'\n",
    "if secrets_path.exists():\n",
    "    with open(secrets_path, 'r') as f:\n",
    "        secrets = toml.load(f)\n",
    "    logger.info(f\"Secrets loaded from {secrets_path}\")\n",
    "else:\n",
    "    logger.warning(f\"No secrets file found at {secrets_path}\")\n",
    "    secrets = {}\n",
    "\n",
    "# Set secrets as environment variables\n",
    "for key, value in secrets.items():\n",
    "    os.environ[key] = str(value)\n",
    "\n",
    "# Import your framework\n",
    "from ssff_framework import StartupFramework\n",
    "\n",
    "# Load the experiment dataset\n",
    "input_path = os.path.join(project_root, 'data', 'Experiment_Dataset.csv')\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Initialize the StartupFramework\n",
    "framework = StartupFramework()\n",
    "\n",
    "# Function to flatten nested dictionaries\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Process each row in the dataset\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing companies\"):\n",
    "    logger.info(f\"Processing company {index + 1}/{len(df)}\")\n",
    "    \n",
    "    # Prepare startup info string\n",
    "    startup_info_str = f\"\"\"\n",
    "    {row['long_description']}\n",
    "    Founder background: {row['paragraph']}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Run analysis\n",
    "    analysis_result = framework.analyze_startup(startup_info_str)\n",
    "    \n",
    "    # Flatten nested dictionaries in the result\n",
    "    flat_result = flatten_dict(analysis_result)\n",
    "    \n",
    "    # Add input data to the result\n",
    "    flat_result['input_description'] = row['long_description']\n",
    "    flat_result['input_founder_background'] = row['paragraph']\n",
    "    flat_result['input_success'] = row['success']\n",
    "    \n",
    "    results.append(flat_result)\n",
    "    \n",
    "    # Log summary of the result\n",
    "    logger.info(f\"Company {index + 1} analysis summary:\")\n",
    "    logger.info(f\"Prediction: {flat_result.get('Categorical Prediction', 'N/A')}\")\n",
    "    logger.info(f\"Overall Score: {flat_result.get('Final Decision_overall_score', 'N/A')}\")\n",
    "    logger.info(f\"Recommendation: {flat_result.get('Final Decision_recommendation', 'N/A')}\")\n",
    "    logger.info(\"---\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV\n",
    "output_path = os.path.join(project_root, 'data', 'Experiment_Results.csv')\n",
    "results_df.to_csv(output_path, index=False)\n",
    "\n",
    "logger.info(f\"Analysis complete. Results saved to {output_path}\")\n",
    "logger.info(f\"Total rows processed: {len(results_df)}\")\n",
    "logger.info(f\"Number of columns in result: {len(results_df.columns)}\")\n",
    "\n",
    "# Display a sample of the results\n",
    "logger.info(\"\\nSample of results:\")\n",
    "logger.info(results_df[['Categorical Prediction', 'Final Decision_overall_score', 'Final Decision_recommendation']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final Analysis_overall_score</th>\n",
       "      <th>Final Analysis_summary</th>\n",
       "      <th>Final Analysis_strengths</th>\n",
       "      <th>Final Analysis_weaknesses</th>\n",
       "      <th>Final Analysis_recommendation</th>\n",
       "      <th>Final Analysis_outcome</th>\n",
       "      <th>Market Analysis_market_size</th>\n",
       "      <th>Market Analysis_growth_rate</th>\n",
       "      <th>Market Analysis_competition</th>\n",
       "      <th>Market Analysis_market_trends</th>\n",
       "      <th>...</th>\n",
       "      <th>Startup Info_team_dynamics</th>\n",
       "      <th>Startup Info_web_traffic_growth</th>\n",
       "      <th>Startup Info_social_media_presence</th>\n",
       "      <th>Startup Info_investment_rounds</th>\n",
       "      <th>Startup Info_regulatory_approvals</th>\n",
       "      <th>Startup Info_patents</th>\n",
       "      <th>input_description</th>\n",
       "      <th>input_founder_background</th>\n",
       "      <th>input_success</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>The startup's mytower platform demonstrates st...</td>\n",
       "      <td>['Comprehensive feature set tailored for high-...</td>\n",
       "      <td>['Potential gaps in technology expertise withi...</td>\n",
       "      <td>It is advisable to further investigate potenti...</td>\n",
       "      <td>Unsuccessful</td>\n",
       "      <td>The exact current market size for smart buildi...</td>\n",
       "      <td>The market is expected to experience a signifi...</td>\n",
       "      <td>The competitive landscape features various pla...</td>\n",
       "      <td>Key trends include the rise of smart apartment...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Unified All-in-One Innovative Property Manag...</td>\n",
       "      <td>Meiri Shemesh is known for their contribution ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Final Analysis_overall_score  \\\n",
       "0                           7.0   \n",
       "\n",
       "                              Final Analysis_summary  \\\n",
       "0  The startup's mytower platform demonstrates st...   \n",
       "\n",
       "                            Final Analysis_strengths  \\\n",
       "0  ['Comprehensive feature set tailored for high-...   \n",
       "\n",
       "                           Final Analysis_weaknesses  \\\n",
       "0  ['Potential gaps in technology expertise withi...   \n",
       "\n",
       "                       Final Analysis_recommendation Final Analysis_outcome  \\\n",
       "0  It is advisable to further investigate potenti...           Unsuccessful   \n",
       "\n",
       "                         Market Analysis_market_size  \\\n",
       "0  The exact current market size for smart buildi...   \n",
       "\n",
       "                         Market Analysis_growth_rate  \\\n",
       "0  The market is expected to experience a signifi...   \n",
       "\n",
       "                         Market Analysis_competition  \\\n",
       "0  The competitive landscape features various pla...   \n",
       "\n",
       "                       Market Analysis_market_trends  ...  \\\n",
       "0  Key trends include the rise of smart apartment...  ...   \n",
       "\n",
       "   Startup Info_team_dynamics Startup Info_web_traffic_growth  \\\n",
       "0                         NaN                             NaN   \n",
       "\n",
       "  Startup Info_social_media_presence Startup Info_investment_rounds  \\\n",
       "0                                NaN                            NaN   \n",
       "\n",
       "   Startup Info_regulatory_approvals  Startup Info_patents  \\\n",
       "0                                NaN                   NaN   \n",
       "\n",
       "                                   input_description  \\\n",
       "0  A Unified All-in-One Innovative Property Manag...   \n",
       "\n",
       "                            input_founder_background input_success error  \n",
       "0  Meiri Shemesh is known for their contribution ...             0   NaN  \n",
       "\n",
       "[1 rows x 70 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the results\n",
    "results_path = '/Users/wangxiang/Desktop/Startup-Success-Forecasting-Framework/data/Experiment_Results_Final.csv'\n",
    "df = pd.read_csv(results_path)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Framework: Run the baseline across 50 startups and store them into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 19:27:41.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-26 19:27:41.889 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No secrets found. Valid paths for a secrets.toml file or secret directories are: /Users/wangxiang/.streamlit/secrets.toml, /Users/wangxiang/Desktop/Startup-Success-Forecasting-Framework/experiments/.streamlit/secrets.toml",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# initialise the baseline framework\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbaseline_framework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaselineFramework\n\u001b[0;32m---> 21\u001b[0m baseline_framework \u001b[38;5;241m=\u001b[39m \u001b[43mBaselineFramework\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(startup_data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(startup_data\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/baseline_framework.py:19\u001b[0m, in \u001b[0;36mBaselineFramework.__init__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/agents/base_agent.py:13\u001b[0m, in \u001b[0;36mBaseAgent.__init__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_api \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIAPI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msecrets \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/utils/api_wrapper.py:19\u001b[0m, in \u001b[0;36mOpenAIAPI.__init__\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m model_name  \u001b[38;5;66;03m# E.g., \"gpt-4-0613\" or \"gpt-4-1106-preview\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Try to get the API key from Streamlit secrets, fall back to environment variable\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m api_key \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecrets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY not found in Streamlit secrets or environment variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<frozen _collections_abc>:774\u001b[0m, in \u001b[0;36mget\u001b[0;34m(self, key, default)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/myenv/lib/python3.11/site-packages/streamlit/runtime/secrets.py:491\u001b[0m, in \u001b[0;36mSecrets.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the value with the given key. If no such key\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mexists, raise a KeyError.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03mThread-safe.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 491\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[key]\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Mapping):\n\u001b[1;32m    493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/Desktop/Startup-Success-Forecasting-Framework/myenv/lib/python3.11/site-packages/streamlit/runtime/secrets.py:393\u001b[0m, in \u001b[0;36mSecrets._parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    388\u001b[0m         secret_error_messages_singleton\u001b[38;5;241m.\u001b[39mget_no_secrets_found_message(\n\u001b[1;32m    389\u001b[0m             file_paths\n\u001b[1;32m    390\u001b[0m         )\n\u001b[1;32m    391\u001b[0m     )\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_exception_if_not_suppressed(error_msg)\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m secrets\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_set_environment_variable(k, v)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No secrets found. Valid paths for a secrets.toml file or secret directories are: /Users/wangxiang/.streamlit/secrets.toml, /Users/wangxiang/Desktop/Startup-Success-Forecasting-Framework/experiments/.streamlit/secrets.toml"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check if the variable is loaded\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "startup_data = pd.read_csv(os.path.join(project_root, 'data', 'Experiment_Dataset.csv'))\n",
    "\n",
    "# initialise the baseline framework\n",
    "from baseline_framework import BaselineFramework\n",
    "\n",
    "baseline_framework = BaselineFramework()\n",
    "\n",
    "print(startup_data.head(1))\n",
    "print(startup_data.shape)\n",
    "\n",
    "# #Process each startup\n",
    "# logger.info(\"Starting startup analysis...\")\n",
    "\n",
    "# for idx, row in tqdm(startup_data.iterrows(), total=len(startup_data), desc=\"Processing startups\"):\n",
    "#     try:\n",
    "#         # Create startup info string\n",
    "#         startup_info_str = f\"\"\"\n",
    "#         {row['long_description']}\n",
    "#         Founder background: {row['paragraph']}\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # Run analysis\n",
    "#         analysis_result = baseline_framework.analyze_startup(startup_info_str)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing startup {idx}: {str(e)}\")\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if the variable is loaded\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
